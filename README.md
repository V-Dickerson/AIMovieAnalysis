# AIMovieAnalysis
This project uses pandas, ChatGPT, and a dataset of movies and their ratings in order to test the capabilities of generative text models in classification for the purpose of expanded data analysis. 

# Background
Generative text models have been growing in popularity in recent months. ChatGPT, recently released to the public by OpenAI, is capable of synthesizing unique text that previously had to be generated by humans. With the rise of this technology, there have been many questions as to the future of its application. Some are more scared, asking "will ChatGPT replace my job?", while others see an opportunity.

# The idea
The idea tested in this paper is that the classification skills of generative text models have broader applications in data science as they can enable users to turn insignificant data sets into larger, more robust, and most importantly, reliable data sets. 

# The implementation
In order to test this, the first step was to find a data set. For this application, a dataset called "tmdb_movies_dataset" was used. You can find that [here](https://www.kaggle.com/datasets/afreentyagi/10000-tmdb-movies-dataset). This dataset provides the names, ratings, and descriptions of 10,000 movies. For the purposes of this application, the descriptions weren't used insofar as the goal was to generate something similar with the model.

The goal was to generate key terms for every movie on the list using a generative model, cleaning up the data to account for errors within GPT's processing, and then finally to find the statistical correlations between ratings and terms for a broad range of movies.

Taking the dataset from its provided form and converting it into something that fits our applications was simple. Here's a snippet of the code used to do so.
```py
def initialize_movie_data():
    with open(read_file, newline='\n', encoding="utf-8") as csv_file:
        movie_reader = csv.reader(csv_file, delimiter=',')
        id = 0
        for line in movie_reader:
            try:
                movie = {
                    'name': line[2],
                    'GPT_description': "",
                    'popularity': line[4],
                    'vote_average': line[6],
                    'vote_count': line[7]

                }
                movie_frame.loc[id] = movie
                #print(movie)
                id += 1
            except Exception as e:
                print(e)
                break
        movie_frame.to_csv("movie_by_terms.csv", sep=',', index=False, encoding='utf-8')
        print(movie_frame)
```

Once the data was in a more usable form, then began the implementation of the AI. The first challenge within that was finding a prompt that would reliably bring clean output. Depending on the model, some text would be more usable than others. Using OpenAI's Ada, it was incapable of following simple directions and describing the movie. However, jumping to ChatGPT 3.5, the model currently active on OpenAI's public site at the time of this writing, it was capable of listening to directions much better.

The final prompt chosen was `Act as a machine that lists the generic themes of provided movies. Provide a list of 15 themes for" + movie + " to help movie-goers know if they would enjoy the movie. The answer must be in the form of a semicolon separated list without any introduction.`. There's a few things of note here. First, the model is told to roleplay as a listing machine. While this may sound insignificant, asking these models to roleplay as some kind of a character can help them to provide more reliable inputs. Furthermore, we ask ChatGPT to provide a list of 15 themes to help movie-goers. Note that it won't return 15 themes -- it's restricted in how much it can output. However, the aim here is to get as many as it will provide and hopefully more creative answers. And finally, we tell the AI exactly how to deliniate the results, as to provide consistent and usable data.

Here's a snippet of the code used to get responses from ChatGPT. 
```py
# Takes movie name and returns the key GPT terms
def run_GPT(movie):
    print(f"RUNNING GPT CHECK ON {movie}")
    content = "Act as a machine that lists the generic themes of provided movies. Provide a list of 15 themes for" + movie + " to help movie-goers know if they would enjoy the movie. The answer must be in the form of a semicolon separated list without any introduction."
    message=[
        {"role": "user", "content": content},
    ]
    chat = openai.ChatCompletion.create(
        model="gpt-3.5-turbo", messages=message,
        max_tokens=20, temperature=1.5
    )
    return chat.choices[0].message["content"]
```

Now, a solution was necessary to loop through our dataset and update it with each response. In doing so, there were a few key problems to begin with. The first was that quite frequently, ChatGPT would be overloaded while calling requests, and it would return something like this --
```
That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID <request_id> in your message.)
```
This posed a problem because without proper handling, it could cause our program to crash, and it would leave gaps within the data. However, this problem was easily solved. First, including error handling that passed through each error request, but more importantly, through how the data was set. 
The dataset was read into a pandas DataFrame, and while looping through the data, it would check for NaN values within the descriptions. Those would exist on any that the model hadn't addressed yet. Then, if there was one of these values, it would call ChatGPT to provide the value for the dataset. Every 25 movies it would save the data, as to keep the temporary data held by the script to a minimum.

This allowed errors to carefully be skipped, and then for the dataset to be fixed upon later iterations, because the requests that returned errors would still be evaluated as NaN by pandas. Here's the code that was used to do that --
```py
def update_movie_details():
    data_set = pd.read_csv('movie_by_terms.csv')
    index = 0
    for i in range(400):
        for j in range(25):
            try:
                if pd.isna(data_set['GPT_description'][i * 25 + j]):
                    print(i * 25 + j)
                    data_set["GPT_description"][i * 25 + j] = run_GPT(data_set["name"][i * 25 + j])
            except Exception as e:
                print(e)
                pass
        data_set.to_csv('movie_by_terms.csv', sep=',', index=False, encoding='utf-8')
```
Note that multiprocessing was considered and would be viable for further and larger implementations, however it was decided to be outside of the scope of this project because the dataset was only 10,000 items, and would take a relatively small amount of time to iterate through so as to make multiprocessing not worth the effort.

Now came the process of cleaning the data. One thing that is evident is that ChatGPT in its current form is definitely not perfect at following directions. Here's an example --
![Screenshot 2023-06-07 111650](https://github.com/V-Dickerson/AIMovieAnalysis/assets/113952778/d8430684-b724-47fc-94b9-c29e1107042f)
What this shows is instances in the dataset where ChatGPT inexplicably decided that it was not allowed to review movies, or where it didn't follow directions. Here are the examples:
```
The High Note,"As an AI language model, I can provide you 15 possible themes for The High Note movie:",9.904,7.1,400
Thursday,"(As an AI language model, I don't have any context about a specific Thursday movie - please",9.68,7.0,263
Cinderella,"As an AI language model, I distinguish different themes in a movie, such as struggles and triumphs",62.132,6.8,6551
Falling in Love,"I'm sorry, as an AI language model, I cannot generate an answers for movies, and can",11.4,6.6,303
Struck by Lightning,"Note: As an AI language model, I do not have personal biases and emotions, hence it is",7.704,6.3,215
The Librarian: Quest for the Spear,"My programmer holds the opinion that as an AI language model, I cannot thoroughly comprehend any given video content",15.874,6.2,565
Like Mike,"As an AI language model, here are some generic themes depicted in the Hollywood movie ""Like Mike"":",12.545,6.1,439
```

Further, at times it wouldn't listen to the formatting specifications demanded. Here are a few short examples.
```
Daylight,Thriller; Disaster; Trapped; Survival; Chaos; Heroism; Engineering feats; Drama;,13.772,6.1,1346
Them,"Love
Coming of age
Family
Friendship 
Adventure 
Drama
Action 
Suspense",6.723,6.1,451
```
```
The Brats,"Bickering divorcees; coming of age; father-daughter conflict...
Note from author: As",3.852,6.1,490
```
```
Desire,"Looking at the movie Desert, here is a list of possible themes that one might find being portrayed;

",94.091,6.1,710
```
```
Eight Legged Freaks,"Mutant creatures, 
Invasion of town/city, 
Heroes saving the day, 
Creature",16.04,5.7,1045
```
These are particularly insidious because they are instances where ChatGPT totally ignored its input and provided an output that could provide major errors within the script, such as when it chose to delineate the items of its response with commas, rather than semicolons. Such errors can cause major problems for reading the file into a dataset.
